{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21f04bf",
   "metadata": {},
   "source": [
    "# Auxiliary Code\n",
    "This script contains the rudimentary Dash application providing a web-based interface serving the user the intrusion-metrics introduced in the main work.\n",
    "Additionally, some function used for both Overlap and Entropy evaluation are given here. The training of ATM is included too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.graph_objs as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "import random\n",
    "from dash.exceptions import PreventUpdate\n",
    "import re\n",
    "import requests as request\n",
    "\n",
    "\n",
    "K = 25\n",
    "\n",
    "#Some generic functions copied from other scripts\n",
    "def read(path):\n",
    "    data = np.matrix(pd.read_csv(path, header=None))\n",
    "    return data\n",
    "\n",
    "\n",
    "def clean_string(s):\n",
    "    s = s.translate(str.maketrans('', '', '[]{}\\'\\\"@.,:;?!=-+/\\\\&`*#^'))\n",
    "    return s\n",
    "\n",
    "\n",
    "def scale(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = (x[i]-np.mean(x[i]))/(np.full( (1,len(x[i])), np.var(x[i])**0.5)[0])\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_proper(data, length):\n",
    "    c = np.zeros((len(data), length))\n",
    "    for i in range(len(data)):\n",
    "        a = data[i, 0].split()\n",
    "        b = [float(n) for n in a]\n",
    "        c[i] = b\n",
    "    return c\n",
    "\n",
    "# Training of ATM author-embeddings\n",
    "def ATM_emb():\n",
    "    meta_raw = np.matrix(pd.read_csv('ATM_meta.txt', delimiter='\\t', header=None))\n",
    "    meta_NEW_2 = []\n",
    "    au_dir = {}\n",
    "    au_dir_i = 0\n",
    "    for i in meta_raw:\n",
    "        cat_list = i[0, 0].replace(' {', '%[')\n",
    "        full = cat_list.rsplit('%', 1)\n",
    "        cats = {}\n",
    "        cat_list = full[1].translate(str.maketrans('', '', '[]{}\\'\\\":,'))\n",
    "        cat_list = cat_list.split()\n",
    "        ind = 0\n",
    "        for i in range(int(len(cat_list) / 2)):\n",
    "            cats[cat_list[ind]] = float(cat_list[ind + 1])\n",
    "            ind += 2\n",
    "        name_nr = str(full[0]).rsplit(' ', 1)\n",
    "        name = name_nr[0]\n",
    "        au_dir[name] = au_dir_i\n",
    "        nr = int(name_nr[1])\n",
    "        meta_NEW_2.append((name, nr, cats))\n",
    "        au_dir_i += 1\n",
    "\n",
    "    au_emb_raw = np.array(pd.read_csv('ATM_embeddings.txt', delimiter='\\t', header=None))\n",
    "    au_emb = []\n",
    "    for i in range(int(len(au_emb_raw))):\n",
    "        a = str(au_emb_raw[i]).translate(str.maketrans('', '', \"[]()\\'\"))\n",
    "        a = a.split(' ')\n",
    "        a = np.array(a).astype(float)\n",
    "        au_emb.append(a)\n",
    "\n",
    "    return meta_NEW_2, au_emb\n",
    "\n",
    "#Fetching CTM generated data to transform it into author-embeddings\n",
    "def CTM_emb():\n",
    "    # scaled Lambda\n",
    "    # Theta\n",
    "    # author embeddings\n",
    "    # Betas as topic-word distributions\n",
    "    # word_inv list\n",
    "\n",
    "    word_inv_raw = str(pd.read_csv('words_inv.txt', delimiter='\\t'))\n",
    "    word_inv_raw = word_inv_raw.split()\n",
    "    words_inv = []\n",
    "    ind = 3\n",
    "    for i in range(int(len(word_inv_raw) / 2 - 2)):\n",
    "        words_inv.append((int(clean_string(word_inv_raw[ind])), clean_string(word_inv_raw[ind + 1])))\n",
    "        ind += 2\n",
    "    print(words_inv)\n",
    "    meta_raw = np.matrix(pd.read_csv('authors.txt', delimiter='\\t', header=None))\n",
    "    meta = []\n",
    "    au_dir = {}\n",
    "    au_dir_i = 0\n",
    "    for i in meta_raw:\n",
    "        cat_list = i[0, 0].replace(' {', '%[')\n",
    "        full = cat_list.rsplit('%', 1)\n",
    "        cats = {}\n",
    "        cat_list = full[1].translate(str.maketrans('', '', '[]{}\\'\\\":,'))\n",
    "        cat_list = cat_list.split()\n",
    "        ind = 0\n",
    "        for i in range(int(len(cat_list) / 2)):\n",
    "            cats[cat_list[ind]] = float(cat_list[ind + 1])\n",
    "            ind += 2\n",
    "        name_nr = str(full[0]).rsplit(' ', 1)\n",
    "        name = name_nr[0]\n",
    "        au_dir[name.replace(' ','')] = au_dir_i\n",
    "        nr = int(name_nr[1])\n",
    "        meta.append((name, nr, cats))\n",
    "        au_dir_i += 1\n",
    "    cum = np.zeros(len(meta)+1)\n",
    "    tot = 0\n",
    "    for i in range(len(cum)-1):\n",
    "        tot += int(meta[i][1])\n",
    "        cum[i+1] = tot\n",
    "    cum = cum.astype(int)\n",
    "    lam = read('lam_raw.txt')\n",
    "    lam = make_proper(lam, K)\n",
    "    theta = lam.copy()\n",
    "    lam = np.transpose(lam)\n",
    "    lam = scale(lam)\n",
    "    lam = np.transpose(lam)\n",
    "\n",
    "    for i in range(len(theta)):\n",
    "        theta[i] = np.exp(theta[i])/sum(np.exp(theta[i]))\n",
    "    auth_embedding = []\n",
    "    hom = []\n",
    "    for j in range(len(cum)-1):\n",
    "        div = np.full((1, K), (cum[j + 1] - cum[j]))[0]\n",
    "        au_ma = theta[cum[j]:cum[j + 1]]\n",
    "\n",
    "        aggregate = []\n",
    "        homogeneity = []\n",
    "        length = len(au_ma[:, 0])\n",
    "        for k in range(K):\n",
    "            so = np.mean((au_ma[:, k]))\n",
    "            aggregate.append(so)\n",
    "            homogeneity.append(np.std(au_ma[:, k]))\n",
    "        div = np.full((1, K), sum(aggregate))[0]\n",
    "        auth_embedding.append(np.array(aggregate)/div)\n",
    "\n",
    "        hom.append(homogeneity)\n",
    "    beta = read('beta_numbers.txt')\n",
    "    beta = make_proper(beta, len(words_inv))\n",
    "\n",
    "    topic_words = []\n",
    "    for j in range(K):\n",
    "        s = list(beta[j])\n",
    "        s_order = []\n",
    "        for i in range(15):\n",
    "            rounded = round(max(s) * 1000) / 1000\n",
    "            s_order.append((words_inv[s.index(max(s))][1]))\n",
    "            s[s.index(max(s))] = -1000\n",
    "        #s_order = np.concatenate(s_order)\n",
    "        topic_words.append(s_order)\n",
    "\n",
    "    return meta, theta, beta, words_inv, lam, auth_embedding, topic_words, au_dir, hom\n",
    "\n",
    "\n",
    "meta_ctm, theta, beta, words_inv, lam, ctm, topic_words, au_dir, hom = CTM_emb()\n",
    "meta_atm, atm = ATM_emb()\n",
    "\n",
    "# Top 15 most probable words for all 25 topic found by Author-Topic Model ATM\n",
    "# Data pasted directly into the scirpt purely for convenience.\n",
    "topics_atm = [[('graph', 0.026917765302258076), ('graphs', 0.024854199437089844), ('polynomials', 0.01364085889383161), ('polynomial', 0.012436260008556688), ('number', 0.011152184493483926), ('paper', 0.00869807335954402), ('degree', 0.008548859861996772), ('prove', 0.008535582972636447), ('vertex', 0.007898386850922867), ('result', 0.007142742627325094), ('vertices', 0.006923188748564399), ('order', 0.006730000744299254), ('problem', 0.006578921135704353), ('functions', 0.0062606397256497566), ('curves', 0.00561847435197247)],\n",
    "[('cohomology', 0.03424839703571942), ('groups', 0.021076238554897934), ('varieties', 0.020031717920019707), ('projective', 0.019062593893231148), ('curve', 0.017037363509516967), ('spaces', 0.01237605046644925), ('p-adic', 0.01051088393837224), ('category', 0.010339573478964227), ('prove', 0.009907199706849222), ('de', 0.009769149692380455), ('give', 0.009544742021662217), ('variety', 0.008416293440641745), ('toric', 0.007920746151645244), ('dialogue', 0.007871645474573552), ('etale', 0.007802945059166217)],\n",
    "[('systems', 0.008602091898961411), ('method', 0.00734056151265936), ('models', 0.006931947517149136), ('spider', 0.00661535948448363), ('function', 0.0063873339260013765), ('functions', 0.005264042416520897), ('results', 0.005050441153336566), ('system', 0.004839139769341751), ('two-body', 0.004777413568846213), ('difference', 0.004775889095938667), ('logics', 0.004757046877584203), ('case', 0.004634491571779287), ('wave', 0.004569437769728256), ('obtained', 0.004379384935289661), ('structures', 0.004333254849552638)],\n",
    "[('clusters', 0.02823518680205423), ('cosmic', 0.020727089234083715), ('energy', 0.019215594152496768), ('cluster', 0.018525908577440083), ('rays', 0.013355709463634326), ('sources', 0.009792741935816847), ('omega', 0.009300190461114015), ('events', 0.008246941315557598), ('high', 0.008186285834900284), ('group', 0.008105382024548292), ('limits', 0.007429509277408303), ('groups', 0.007339735670399495), ('ray', 0.007329463696356714), ('gamma', 0.0071612784874703446), ('primitive', 0.0066562893237170845)],\n",
    "[('stars', 0.02895570307588757), ('star', 0.012926819238266139), ('stellar', 0.011361878024513055), ('-', 0.00819137091766117), ('data', 0.008035438857739323), ('planets', 0.007898757587636406), ('planet', 0.0061769596553892196), ('lines', 0.005725700629040567), ('hd', 0.00563019848422455), ('dwarfs', 0.005239653551734377), ('results', 0.005123033108388986), ('binary', 0.005020404249164267), ('sample', 0.00479719711195336), ('mass', 0.004788760836826252), ('emission', 0.0046678405644504945)],\n",
    "[('algorithm', 0.010158806093734818), ('model', 0.00894469426705352), ('data', 0.008508128841772706), ('paper', 0.008254545980433669), ('method', 0.008093669597411982), ('control', 0.0077507401938722836), ('approach', 0.007198724957381025), ('methods', 0.006639699582438891), ('models', 0.006431522574466201), ('algorithms', 0.006299518598958458), ('performance', 0.005698085937010215), ('network', 0.005477071883070981), ('based', 0.005220205276623002), ('networks', 0.00507705308906194), ('learning', 0.005033901870133361)],\n",
    "[('solar', 0.02459522305124114), ('disk', 0.009591236766560781), ('model', 0.0078002077429142), ('coronal', 0.007787078520944417), ('disks', 0.006208068208026155), ('flux', 0.005932707928548644), ('data', 0.0058128038869933825), ('disease', 0.005765073438788722), ('protoplanetary', 0.00561540743808622), ('fast', 0.005176120001719363), ('region', 0.005020203280286625), ('images', 0.004993357034749879), ('open', 0.004953429850351063), ('methods', 0.00488160800904751), ('method', 0.00486136844872404)],\n",
    "[('radio', 0.02434743988347047), ('x-ray', 0.02256813869006823), ('emission', 0.012860049721275885), ('bursts', 0.011853172177052826), ('source', 0.011748385355240105), ('sources', 0.010972944853659227), ('pulsars', 0.010770501057177102), ('observations', 0.010422779726925624), ('data', 0.008473814412664602), ('burst', 0.008208151094278828), ('pulsar', 0.007858631500044051), ('array', 0.007614550366314202), ('frb', 0.007376455990606105), ('mhz', 0.006735825921109535), ('frequency', 0.006618640607268792)],\n",
    "[('magnetic', 0.027823526901183605), ('field', 0.020902425221360887), ('transition', 0.016870887443365994), ('phase', 0.014995960166601069), ('temperature', 0.00903800339515248), ('lattice', 0.008587725809061295), ('state', 0.008557855327235965), ('behavior', 0.008125125817340182), ('critical', 0.007666107210707905), ('josephson', 0.0069227202362744595), ('range', 0.006324047139086514), ('superconductors', 0.00606819648516439), ('superconducting', 0.005995222852692164), ('vortex', 0.0059614553693571595), ('frequency', 0.005767586532968784)],\n",
    "[('network', 0.015961914726665246), ('fractional', 0.013897668609664444), ('social', 0.01160863223250222), ('networks', 0.00715362346384956), ('analysis', 0.0067838756313995), ('continuation', 0.0059213175002318695), ('brand', 0.0057946055628842795), ('semantic', 0.0054764692766291895), ('pricing', 0.0053160446908089775), ('online', 0.004884734679977284), ('importance', 0.004786756020110992), ('based', 0.004781336817114515), ('envelope', 0.004730064418994664), ('centrality', 0.004717516759109103), ('option', 0.0046966284426009156)],\n",
    "[('mass', 0.009420467157995232), ('supernova', 0.009164360439386265), ('explosion', 0.008262072021342059), ('membrane', 0.007893373668176268), ('supernovae', 0.007841926683222747), ('models', 0.007672637893404693), ('ejecta', 0.0075358264261329595), ('collapse', 0.0072777894411990025), ('protein', 0.0070165392980166014), ('neutron', 0.006444499648619587), ('white', 0.006031306072827349), ('star', 0.006029951930985179), ('core', 0.005961608279439267), ('simulations', 0.005701032010512537), ('observed', 0.005669452475702237)],\n",
    "[('galaxies', 0.01631902111635705), ('galaxy', 0.010098966074639129), ('sn', 0.008755410063268307), ('-', 0.008577937725711639), ('mass', 0.007202536973354877), ('observations', 0.007178854356388156), ('emission', 0.006809353433443321), ('star', 0.006376990834557747), ('type', 0.0059260733924462695), ('optical', 0.005880797425744501), ('find', 0.0057804893125768435), ('spectra', 0.005280266100070827), ('stellar', 0.00511535662294156), ('redshift', 0.004970994481983461), ('ia', 0.004896424877041654)],\n",
    "[('theory', 0.017282379308754686), ('model', 0.016375813052261785), ('solutions', 0.011846977232910906), ('equations', 0.00908798098308249), ('field', 0.009069413405134882), ('equation', 0.007848377725860233), ('models', 0.007727005077880064), ('general', 0.007624878500455186), ('study', 0.007384185247620273), ('theories', 0.00705955315673265), ('space', 0.006716258960906744), ('case', 0.006651763986191244), ('terms', 0.006359087660883761), ('quantum', 0.006125775636262947), ('limit', 0.0055256370390349505)],\n",
    "[('pi', 0.010971791883396708), ('collisions', 0.01037138998805461), ('states', 0.010187954950030265), ('chiral', 0.007991000375941653), ('interaction', 0.00796128385091702), ('nuclear', 0.007653022479201449), ('data', 0.007029626591568743), ('meson', 0.006662855155279503), ('state', 0.0065011712019338985), ('resonance', 0.006405147257599282), ('reaction', 0.006401004489439126), ('find', 0.0063146403685690414), ('heavy', 0.006204984230464837), ('decay', 0.006098051045898094), ('experimental', 0.0059815062394389966)],\n",
    "[('states', 0.016230316597905452), ('quantum', 0.014071855898951081), ('phase', 0.01396965743262585), ('spin', 0.013390999069906399), ('symmetry', 0.011413262932337976), ('state', 0.010332791734510806), ('topological', 0.009717189420743916), ('phases', 0.008073423999916545), ('magnetic', 0.007359148638974835), ('band', 0.006880433118875921), ('energy', 0.00671067420911757), ('interactions', 0.006624713464217474), ('interaction', 0.006555334714049843), ('graphene', 0.006458355319350656), ('hall', 0.006196467927738449)],\n",
    "[('gravitational', 0.011573405046869288), ('ligo', 0.01014716052452425), ('advanced', 0.008737653516434048), ('quantum', 0.007387314674852656), ('wave', 0.007314833790582421), ('noise', 0.006712234856978012), ('search', 0.006472273013670875), ('detectors', 0.006285032214279133), ('gravitational-wave', 0.006063909422541422), ('waves', 0.005996041929738789), ('bps', 0.005505541880760517), ('binary', 0.0054434836392832624), ('sensitivity', 0.0052720843080652155), ('observing', 0.0052628520857405745), ('detection', 0.005249307022509934)],\n",
    "[('solid', 0.016336099957585223), ('algebras', 0.01513122368546109), ('sphere', 0.009951559222719411), ('pure', 0.00794038438734304), ('monotone', 0.007723253487907199), ('noncommutative', 0.0073781804547367715), ('bd', 0.007217514765076565), ('systems', 0.007096701891493523), ('integrals', 0.007072190329295734), ('liouville', 0.0069527745767205915), ('galilean', 0.006683480447035999), ('momentum', 0.00608720832963296), ('integral', 0.0056553707371958814), ('integrable', 0.005387567097402383), ('instability', 0.005361627128355224)],\n",
    "[('neutrino', 0.014849818372632922), ('dark', 0.014565441410067027), ('matter', 0.012351099984626357), ('model', 0.011953245048978186), ('mass', 0.010198537348240127), ('cosmological', 0.007716827256107242), ('energy', 0.0073007988777721924), ('scale', 0.007282930981439528), ('data', 0.006517688815070836), ('standard', 0.006306034144232358), ('spectrum', 0.005992473908015049), ('measurements', 0.005622486976416088), ('background', 0.005450998989575454), ('large', 0.005281765364534711), ('neutrinos', 0.005268267512753158)],\n",
    "[('estimates', 0.017218711336680452), ('li', 0.00995643715731854), ('singularities', 0.008072946775464652), ('orthogonal', 0.007579798514061946), ('reactions', 0.007545171491395861), ('hypersurfaces', 0.0071141704909752496), ('transfer', 0.0069110328764548454), ('range', 0.005936106713138618), ('hera', 0.005805865450602945), ('functions', 0.005627131454242552), ('accumulation', 0.005556511439680785), ('weighted', 0.005494987428654168), ('cross-sections', 0.005485789374321409), ('obtain', 0.005385100318536857), ('wrt', 0.005248206277280469)],\n",
    "[('system', 0.017720566862072788), ('dynamics', 0.01597701880464459), ('three-body', 0.01312743880035231), ('systems', 0.01151030750360423), ('stochastic', 0.01092180571242395), ('gas', 0.010539937642633883), ('results', 0.010301603265805129), ('quantum', 0.008860035726179842), ('interactions', 0.007979850698147538), ('scattering', 0.00785344676755621), ('parameters', 0.007451696822315718), ('probability', 0.007180818404138221), ('regime', 0.006990542536040542), ('study', 0.006472999252467711), ('classical', 0.006415942921385591)],\n",
    "[('detector', 0.02052962276436656), ('data', 0.016110378684736984), ('-', 0.01126609220305011), ('decays', 0.010104589649313645), ('measurements', 0.009584123423120941), ('decay', 0.008403627531122062), ('experiment', 0.00808632137228277), ('resolution', 0.0076976266929537395), ('pm', 0.007551067651355134), ('lhcb', 0.006670274786207887), ('measurement', 0.006536601160159215), ('time', 0.0061878748554633324), ('measured', 0.006159365951248237), ('system', 0.0056061651274643964), ('energy', 0.0054886127938898075)],\n",
    "[('magnetic', 0.024128842687208746), ('field', 0.016998560740299387), ('simulations', 0.010850846679585266), ('accretion', 0.010689346759124007), ('gas', 0.01019023040302734), ('flow', 0.00975321112598313), ('disk', 0.008878964238963382), ('large', 0.008828544943761556), ('density', 0.007693008317888466), ('plasma', 0.0075592733725802766), ('hall', 0.007533762884131175), ('bilayer', 0.00709842690094283), ('model', 0.0069660269038755215), ('molecular', 0.006560798811641058), ('turbulence', 0.006090234340541753)],\n",
    "[('black', 0.03918612457903383), ('hole', 0.02488860626704141), ('holes', 0.01625900089780286), ('field', 0.0161725095648634), ('energy', 0.01534038163708876), ('magnetic', 0.012621161412151801), ('mass', 0.011174105209960141), ('fields', 0.010539288361198459), ('cme', 0.008241287500985735), ('massive', 0.008171975610740253), ('gravitational', 0.007854085241545915), ('gravity', 0.00717196193708561), ('particles', 0.007100562908928894), ('tau', 0.005855461587811541), ('corona', 0.005725861910098842)],\n",
    "[('time', 0.017971713049777533), ('entropy', 0.011656571763564976), ('finite', 0.007314352165743925), ('entanglement', 0.0072415560684786565), ('random', 0.006756825206902677), ('simple', 0.006580754975102543), ('model', 0.005422473163473427), ('terms', 0.005201617362426342), ('sequence', 0.004892078343192732), ('results', 0.004597016629379385), ('theory', 0.004495648624223556), ('present', 0.004302486330414779), ('series', 0.0042575112546789605), ('local', 0.004100860914251018), ('general', 0.0037791709885981115)],\n",
    "[('quantum', 0.01675920030930548), ('field', 0.01658763904679444), ('light', 0.014308623177037818), ('laser', 0.01349821848181303), ('energy', 0.013442349145134277), ('optical', 0.009664871073679152), ('photon', 0.009197107241324233), ('polarization', 0.009043628851791302), ('scattering', 0.008744104128093356), ('control', 0.007896543801504494), ('atomic', 0.007327152251500056), ('photons', 0.007110770627111839), ('coherent', 0.006842393821508134), ('electron', 0.005966078688606557), ('large', 0.005958918916515672)]\n",
    "]\n",
    "\n",
    "# Creation of bag of words type representation for individual authors\n",
    "def resemble(emb, num):\n",
    "    betaC = beta.copy()\n",
    "    embc = list(emb).copy()\n",
    "    auth_words = []\n",
    "    for i in range(num):\n",
    "        m = np.max(embc)\n",
    "        m_ind = embc.index(m)\n",
    "        embc[m_ind] = 0\n",
    "        w = []\n",
    "        BC = list(betaC[m_ind])\n",
    "        for j in range(15):\n",
    "            maximum = np.max(BC)\n",
    "            max_ind = BC.index(maximum)\n",
    "            w.append(words_inv[max_ind][1])\n",
    "            BC[max_ind] = 0\n",
    "        wr = random.sample(w, 5)\n",
    "        auth_words.append(wr)\n",
    "    #print(auth_words)\n",
    "    return auth_words\n",
    "\n",
    "\n",
    "def resemble_atm(x, nr):\n",
    "    emb = list(x)\n",
    "    auth_words = []\n",
    "    for i in range(nr):\n",
    "        T = []\n",
    "        m_ind = emb.index(np.max(emb))\n",
    "        emb[m_ind] = 0\n",
    "        for e in range(len(topics_atm[m_ind])):\n",
    "            T.append(topics_atm[m_ind][e][0])\n",
    "        auth_words.append(random.sample(T, 5))\n",
    "    return auth_words\n",
    "\n",
    "\n",
    "def mass(emb):\n",
    "    emb = list(emb)\n",
    "    mass = 0\n",
    "    for i in range(len(emb)):\n",
    "        mass += np.max(emb)\n",
    "        emb[emb.index(np.max(emb))] = 0\n",
    "        if mass > 0.7:\n",
    "            return i+1\n",
    "\n",
    "# Evaluation of entropy for author-embeddings\n",
    "def entropy(emb):\n",
    "    s = 0\n",
    "    for i in range(len(emb)):\n",
    "        if emb[i] > 0:\n",
    "            s += -emb[i]*np.log(emb[i])\n",
    "        else:\n",
    "            s += 0\n",
    "    return s\n",
    "# ATM entropy: 1.4130466823098162\n",
    "# ATM ent.var: 0.27280902341488183\n",
    "\n",
    "# CTM entropy: 1.6494478999179074\n",
    "# CTM ent.var: 0.2746876079034711\n",
    "E = 0\n",
    "V = []\n",
    "for j in range(len(atm)):\n",
    "    #print(j)\n",
    "    e = entropy(ctm[j])\n",
    "    E += e\n",
    "    V.append(e)\n",
    "print(\"HERE: \", E/len(atm))\n",
    "print(\"VAR: \", np.var(V))\n",
    "# some global variabels \n",
    "A = -1\n",
    "B = -1\n",
    "C = -1\n",
    "D = -1\n",
    "true_intruder = -1\n",
    "true_target = -1\n",
    "true_bestmatch = -1\n",
    "true_second = -1\n",
    "solutions = []\n",
    "\n",
    "# Fetching of random abstract given target author\n",
    "def snippit(au, meta_x):\n",
    "    query_author = '%22' + au + '%22'\n",
    "    start = int(np.floor(random.uniform(0, 1) * meta_x[au_dir[au.replace(' ','')]][1]))\n",
    "    c = []\n",
    "    url = 'http://export.arxiv.org/api/query?search_query=' + query_author + '&start=' + str(start) + '&max_results=1'\n",
    "    data = request.get(url)\n",
    "    data = str(data.content)\n",
    "    data = data.replace('<title>', 'XSX')\n",
    "    data = data.replace('</summary>', 'XSX')\n",
    "    data = data.replace('<entry>', 'DSFGC')\n",
    "    data_split = data.split('DSFGC')\n",
    "    for i in range(len(data_split) - 1):\n",
    "        data_split_part = data_split[i + 1].split('XSX')\n",
    "        title_abstract = str(data_split_part[1])\n",
    "        title_abstract = title_abstract.replace('</title>', '')\n",
    "        title_abstract = title_abstract.replace('<summary>', '_title_split_')\n",
    "        title_abstract = title_abstract.replace('\\\\n', ' ')\n",
    "    title_abstract = title_abstract.split('_title_split_')\n",
    "    c.append(clean_string(title_abstract[0]))\n",
    "    c.append(clean_string(title_abstract[1]))\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def intrude(x, emb, which_meta, resemb):\n",
    "    target = emb[x]\n",
    "    m_target = mass(target)\n",
    "    L = 1\n",
    "    U = 5\n",
    "    if m_target in [1,2]:\n",
    "        L = 1\n",
    "        U = 2\n",
    "    elif m_target == 3:\n",
    "        L= 2\n",
    "        U = 3\n",
    "    elif m_target == 4:\n",
    "        L = 3\n",
    "        U = 4\n",
    "    dist_ctm = []\n",
    "    for a in emb:\n",
    "        dist_ctm.append((1 / (2 ** 0.5)) * (sum(((target ** 0.5 - a ** 0.5) ** 2))) ** 0.5)\n",
    "    dist_ctm_sorted = []\n",
    "    for i in range(len(emb)):\n",
    "        ctm_min = np.min(dist_ctm)\n",
    "        dist_ctm_sorted.append(which_meta[dist_ctm.index(ctm_min)][0])\n",
    "        dist_ctm[dist_ctm.index(ctm_min)] = 2\n",
    "    reps = 0\n",
    "    while True:\n",
    "        r_one_rand = int(1+np.floor(10*random.uniform(0, 1)))\n",
    "        r_two_rand = int(r_one_rand+np.floor(10*random.uniform(0, 1)))\n",
    "        recom_one = list(emb[au_dir[(dist_ctm_sorted[r_one_rand]).replace(' ', '')]])\n",
    "        recom_two = list(emb[au_dir[(dist_ctm_sorted[r_two_rand]).replace(' ', '')]])\n",
    "        rand = int(40 + np.floor(random.uniform(0, 1) * 10))\n",
    "        intruder = dist_ctm_sorted[rand]\n",
    "        meta_index = au_dir[intruder.replace(' ', '')]\n",
    "        emb_intruder = list(emb[meta_index])\n",
    "        if (mass(recom_one) in [L,U] and\n",
    "            mass(recom_two) in [L,U] and\n",
    "            mass(emb_intruder) in [L,U]):\n",
    "            break\n",
    "        if reps > 100:\n",
    "            print('RECALL')\n",
    "            intrude(int(np.floor(random.uniform(0, 1)*238)), emb, which_meta, resemb)\n",
    "            break\n",
    "\n",
    "        reps += 1\n",
    "\n",
    "    global A, B, C, D\n",
    "    A = resemb(target, mass(target))\n",
    "    B = resemb(recom_one, mass(recom_one))\n",
    "    C = resemb(recom_two, mass(recom_two))\n",
    "    D = resemb(emb_intruder, mass(emb_intruder))\n",
    "    solutions.append({'intrusion':D, 'target':A, 'best_recom':B, 'best_recom_two':C})\n",
    "    group = [A,B,C,D]\n",
    "    group_shuffled = random.sample(group, 4)\n",
    "    #for i in range(len(group_shuffled)):\n",
    "        #print(group_shuffled[i])\n",
    "    abc = ['A', 'B', 'C', 'D']\n",
    "    global true_intruder, true_target, true_bestmatch, true_second\n",
    "    true_intruder = abc[group_shuffled.index(D)]\n",
    "    true_target = abc[group_shuffled.index(A)]\n",
    "    true_bestmatch = abc[group_shuffled.index(B)]\n",
    "    true_second = abc[group_shuffled.index(C)]\n",
    "    s = snippit(which_meta[x][0], which_meta)\n",
    "    return group_shuffled, s\n",
    "\n",
    "\n",
    "which_one = -1\n",
    "def CTMvsATM():\n",
    "    global which_one\n",
    "    which_one = random.uniform(0,1)\n",
    "    if which_one > 0.5:\n",
    "        # ATM if > 0.5\n",
    "        ra = int(np.floor(random.uniform(0, 1)*238))\n",
    "        shuffle, s = intrude(ra, atm, meta_atm, resemble_atm)\n",
    "        np.savetxt('ATMorCTM.txt', [which_one], fmt='%s')\n",
    "    else:\n",
    "        # CTM if < 0.5\n",
    "        ra = int(np.floor(random.uniform(0, 1)*238))\n",
    "        shuffle, s = intrude(ra, ctm, meta_ctm, resemble)\n",
    "    a, b, c, d = shuffle\n",
    "\n",
    "    return a, b, c, d, s\n",
    "\n",
    "#Compare recommendation overlap between CTM-embedding and ATM\n",
    "def compare(a, b, depth):\n",
    "    first_recom = -len(a)\n",
    "    for j in range(len(a)):\n",
    "        fitsr_recom_i = -depth\n",
    "        target = j\n",
    "        dist_ctm=[]\n",
    "        dist_atm=[]\n",
    "        for ctm, atm in zip(a, b):\n",
    "            dist_ctm.append((1/(2**0.5))*(sum(((a[target]**0.5-ctm**0.5)**2)))**0.5)\n",
    "            dist_atm.append((1/(2**0.5))*(sum(((b[target]**0.5-atm**0.5)**2)))**0.5)\n",
    "        dist_ctm_sorted=[]\n",
    "        dist_atm_sorted=[]\n",
    "        for i in range(depth):\n",
    "            ctm_min=np.min(dist_ctm)\n",
    "            atm_min=np.min(dist_atm)\n",
    "            dist_ctm_sorted.append(meta_ctm[dist_ctm.index(ctm_min)][0])\n",
    "            dist_atm_sorted.append(meta_atm[dist_atm.index(atm_min)][0])\n",
    "            #if dist_ctm_sorted[i] == dist_atm_sorted[i]:\n",
    "            #    first_recom+=1\n",
    "            dist_ctm[dist_ctm.index(ctm_min)]=2\n",
    "            dist_atm[dist_atm.index(atm_min)]=2\n",
    "        #print(dist_ctm_sorted)\n",
    "        #print(dist_atm_sorted)\n",
    "        for e in range(depth):\n",
    "            if dist_ctm_sorted[e] in dist_atm_sorted:\n",
    "                first_recom+=1\n",
    "                fitsr_recom_i+=1\n",
    "        #if fitsr_recom_i == -depth+1:\n",
    "            #print(j, meta_ctm[j][0])\n",
    "            #print(dist_ctm_sorted)\n",
    "            #print(dist_atm_sorted)\n",
    "\n",
    "    #print(first_recom/((depth-1)*len(a)))\n",
    "    return first_recom/((depth-1)*len(a))\n",
    "\n",
    "\n",
    "#print(compare(ctm, atm, 5))\n",
    "\n",
    "# 69 Katherine E. Whitaker\n",
    "#1-   0.1932\n",
    "#5-   0.297\n",
    "#10-  0.3525\n",
    "#25 - 0.458\n",
    "#119- 0.72\n",
    "#238- 1.0\n",
    "\n",
    "\n",
    "def cleanup(a):\n",
    "    a = a.replace(\"], [\",'SPLITTER_XXX')\n",
    "    a = a.translate(str.maketrans('', '', \"[]\\'\"))\n",
    "    a = a.replace(',', ' ')\n",
    "    a = a.split('SPLITTER_XXX')\n",
    "    a_new = []\n",
    "    for i in range(len(a)):\n",
    "        a_new.append(a[i])\n",
    "    a_new = random.sample(a_new, len(a_new))\n",
    "    a_new_with_breaks = []\n",
    "    for j in range(len(a_new)):\n",
    "        a_new_with_breaks.append(a_new[j])\n",
    "        a_new_with_breaks.append(html.Br())\n",
    "    return a_new_with_breaks\n",
    "\n",
    "# DASH app\n",
    "app = dash.Dash(__name__)\n",
    "app.title = 'Intrusion Metric Survey'\n",
    "\n",
    "# DASH HTML layout\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.H4(id='abstractTitle'),\n",
    "        html.P(id='abstractText', style={'margin-bottom':'2%'}),\n",
    "        html.Div('A',id='canvasA', style={'background-color':'rgba(193, 220, 255, 1)','padding':'10px'}),\n",
    "        html.Div('B', id='canvasB', style={'padding':'10px','background-color':'rgba(236, 242, 251, 1)'}),\n",
    "        html.Div('C', id='canvasC', style={'background-color':'rgba(193, 220, 255, 1)','padding':'10px'}),\n",
    "        html.Div('D', id='canvasD', style={'padding':'10px','background-color':'rgba(236, 242, 251, 1)'  }),\n",
    "    ], id='canvas', style={'text-align':'center'}),\n",
    "    html.Div([\n",
    "    html.Button('A', id=\"A\", style={'width':'15%'}),\n",
    "    html.Button('B', id=\"B\", style={'width':'15%'}),\n",
    "    html.Button('C', id=\"C\", style={'width':'15%'}),\n",
    "    html.Button('D', id=\"D\", style={'width':'15%'})],\n",
    "        id='buttons', style={'text-align':'center','margin-top':'1%'}),\n",
    "    html.H2(id='answerText', style={'text-align':'center'}),\n",
    "    html.Button('Generate Task', id='init', style={'position':'relative', 'color':'rgb(0, 109, 255)'}),\n",
    "\n",
    "    ], style={'background-color':'rgba(145, 148, 179, 0.2)'})\n",
    "\n",
    "app.scripts.append_script({\n",
    "    'external_url': '/assets/style.css'\n",
    "})\n",
    "\n",
    "#DASH functions\n",
    "@app.callback(\n",
    "    Output(component_id='canvasA', component_property='children'),\n",
    "    Output(component_id='canvasB', component_property='children'),\n",
    "    Output(component_id='canvasC', component_property='children'),\n",
    "    Output(component_id='canvasD', component_property='children'),\n",
    "    Output(component_id='abstractTitle', component_property='children'),\n",
    "    Output(component_id='abstractText', component_property='children'),\n",
    "    Input(component_id='init', component_property='n_clicks')\n",
    ")\n",
    "def paint(n_clicks):\n",
    "    a, b, c, d, s = CTMvsATM()\n",
    "    a = cleanup(str(a))\n",
    "    b = cleanup(str(b))\n",
    "    c = cleanup(str(c))\n",
    "    d = cleanup(str(d))\n",
    "    return a, b, c, d, s[0], s[1]\n",
    "\n",
    "@app.callback(\n",
    "    Output('answerText', 'children'),\n",
    "    Output('A', 'n_clicks'),\n",
    "    Output('B', 'n_clicks'),\n",
    "    Output('C', 'n_clicks'),\n",
    "    Output('D', 'n_clicks'),\n",
    "    Input('A', 'n_clicks'),\n",
    "    Input('B', 'n_clicks'),\n",
    "    Input('C', 'n_clicks'),\n",
    "    Input('D', 'n_clicks'),\n",
    "    Input('init', 'n_clicks')\n",
    ")\n",
    "def buttonAnswer(A, B, C, D, init):\n",
    "    print(A, B, C, D, init)\n",
    "    ctx = dash.callback_context\n",
    "    button_id = ''\n",
    "    if ctx.triggered:\n",
    "        if not ctx.triggered[0]['prop_id'].split('.')[0] == 'init':\n",
    "            if which_one > 0.5:\n",
    "                wo = 'ATM'\n",
    "            else:\n",
    "                wo = 'CTM'\n",
    "            button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "            if button_id == true_intruder:\n",
    "                button_id = 'Model:'+wo+'; Correctly identified intruder'\n",
    "            else:\n",
    "                abc = ['Target Author', 'Best Match', 'Second Best Match']\n",
    "                set_of_answers = [true_target, true_bestmatch, true_second]\n",
    "                button_id = 'Model: '+wo+'; False Answer, intruder is '+true_intruder+'. You selected the '+abc[set_of_answers.index(button_id)]\n",
    "        else:\n",
    "            button_id = ''\n",
    "    return button_id, 0, 0, 0, 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   app.run_server(debug=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
